{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> MODEL IMPLEMENTATIONS <h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Imports <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cupy as cp\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Import and Split <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                              title  \\\n",
      "0   0  اریان خان نے والد کی سب سے بڑی خوبی بتا دی انٹ...   \n",
      "1   1  اداکارہ صحیفہ جبار نے تیزی سے اپنا وزن کیسے کم...   \n",
      "2   2  کرائم پٹرول کے نوجوان اداکار کی اچانک موت بھار...   \n",
      "3   3  دیپیکا کی بیٹی کے ہمراہ پہلی جھلک سوشل میڈیا پ...   \n",
      "4   4  سدھارتھ ملہوترا ماروتی سوزوکی کی مقبول گاڑی ڈز...   \n",
      "\n",
      "                                                link  \\\n",
      "0  https://www.express.pk/story/2732283/arian-kha...   \n",
      "1  https://www.express.pk/story/2732277/adakara-s...   \n",
      "2  https://www.express.pk/story/2732263/crime-pet...   \n",
      "3  https://www.express.pk/story/2732253/deepika-k...   \n",
      "4  https://www.express.pk/story/2732223/sidharthm...   \n",
      "\n",
      "                                             content     gold_label  \\\n",
      "0  بالی ووڈ سپر اسٹار شاہ رخ خان بڑے بیٹے اریان خ...  entertainment   \n",
      "1  پاکستان شوبز خوبرو اداکارہ ماڈل صحیفہ جبار خٹک...  entertainment   \n",
      "2  بھارت ٹیلی ویژن اداکار نیتن چوہان گھر سے لاش ب...  entertainment   \n",
      "3  ممبئی بالی وڈ مشہور جوڑی دیپیکا پڈوکون رنویر س...  entertainment   \n",
      "4  ماروتی سوزوکی انڈیا لمیٹڈ نے اپنی مقبول گاڑی ڈ...  entertainment   \n",
      "\n",
      "   content_length  \n",
      "0             204  \n",
      "1             229  \n",
      "2             264  \n",
      "3             236  \n",
      "4             150  \n"
     ]
    }
   ],
   "source": [
    "path = r\"Dataset\\articles.csv\"\n",
    "data = pd.read_csv(path)\n",
    "# print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1594,)\n",
      "X_test shape: (399,)\n",
      "Y_train shape: (1594,)\n",
      "Y_test shape: (399,)\n"
     ]
    }
   ],
   "source": [
    "X = data['content']\n",
    "Y = data['gold_label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Y_train shape: {Y_train.shape}\")\n",
    "print(f\"Y_test shape: {Y_test.shape}\")\n",
    "\n",
    "import torch\n",
    "\n",
    "category_to_label = {\n",
    "    \"entertainment\": 0,\n",
    "    \"business\": 1,\n",
    "    \"sports\": 2,\n",
    "    \"science-technology\": 3,\n",
    "    \"international\": 4\n",
    "}\n",
    "\n",
    "Y_train = [category_to_label[label.strip()] for label in Y_train if label.strip() in category_to_label]\n",
    "Y_test = [category_to_label[label.strip()] for label in Y_test if label.strip() in category_to_label]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Bag of Words <h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor:\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.vocabulary = {}\n",
    "    \n",
    "    def build_vocabulary(self):\n",
    "        unique_words = set()\n",
    "        for sentence in self.dataset:\n",
    "            unique_words.update(sentence.split())\n",
    "        self.vocabulary = {word: idx for idx, word in enumerate(sorted(unique_words))}\n",
    "        return self.vocabulary\n",
    "    \n",
    "    def sentence_to_bow(self, sentence):\n",
    "        bow_vector = [0] * len(self.vocabulary)\n",
    "        for word in sentence.split():\n",
    "            if word in self.vocabulary:\n",
    "                bow_vector[self.vocabulary[word]] += 1\n",
    "        return bow_vector\n",
    "    \n",
    "    def vectorize_sentences(self, X):\n",
    "        return [self.sentence_to_bow(sentence) for sentence in X]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = TextProcessor(X_train)\n",
    "vocab = bag.build_vocabulary()\n",
    "train_x = bag.vectorize_sentences(X_train)\n",
    "test_x = bag.vectorize_sentences(X_test)\n",
    "# print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Neural Network Using Pytorch <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "print(set(Y_train))\n",
    "\n",
    "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "test_x = torch.tensor(test_x, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.long)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.long)\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(train_x, Y_train)\n",
    "test_dataset = TensorDataset(test_x, Y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NewsClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NewsClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 128) \n",
    "        self.fc4 = nn.Linear(128, num_classes) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))   \n",
    "        x = self.fc4(x)          \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = train_x.shape[1]\n",
    "num_classes = len(Y_train.unique())\n",
    "model = NewsClassifier(input_size, num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.6065\n",
      "Epoch [2/5], Loss: 0.0594\n",
      "Epoch [3/5], Loss: 0.0198\n",
      "Epoch [4/5], Loss: 0.0101\n",
      "Epoch [5/5], Loss: 0.0065\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function\n",
    "def evaluate_model(loader, model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in loader:\n",
    "            outputs = model(batch_x)\n",
    "            _, predicted = torch.max(outputs, 1)  \n",
    "            total += batch_y.size(0)\n",
    "            correct += (predicted == batch_y).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "train_accuracy = evaluate_model(train_loader, model)\n",
    "test_accuracy = evaluate_model(test_loader, model)\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Test Accuracy: 0.9649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X_train, X_test, Y_train, Y_test are already defined and preprocessed\n",
    "\n",
    "# Standardizing the features (Logistic Regression usually benefits from feature scaling)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = train_x   # Fit and transform on training data\n",
    "X_test_scaled = test_x       # Only transform on test data\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000, multi_class='ovr', solver='liblinear')  # Solver 'liblinear' is good for smaller datasets\n",
    "model.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "train_predictions = model.predict(X_train_scaled)\n",
    "test_predictions = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(Y_train, train_predictions)\n",
    "test_accuracy = accuracy_score(Y_test, test_predictions)\n",
    "\n",
    "# Print accuracies\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy (Naive Bayes): 0.9806\n",
      "Test Accuracy (Naive Bayes): 0.9674\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "model_nb = MultinomialNB()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model_nb.fit(X_train_scaled, Y_train)\n",
    "\n",
    "# Make predictions on both train and test datasets\n",
    "train_predictions_nb = model_nb.predict(X_train_scaled)\n",
    "test_predictions_nb = model_nb.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy_nb = accuracy_score(Y_train, train_predictions_nb)\n",
    "test_accuracy_nb = accuracy_score(Y_test, test_predictions_nb)\n",
    "\n",
    "# Print accuracies\n",
    "print(f\"Training Accuracy (Naive Bayes): {train_accuracy_nb:.4f}\")\n",
    "print(f\"Test Accuracy (Naive Bayes): {test_accuracy_nb:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
